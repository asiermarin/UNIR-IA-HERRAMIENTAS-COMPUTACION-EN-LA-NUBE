{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Classification for Disaster Risk Reduction with DenseNet-161\n",
    "[![Open In Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/aws/studio-lab-examples/blob/main/computer-vision/weather-data/weather-image-classification-pytorch.ipynb)\n",
    "\n",
    "\n",
    " Today we are going to work with a weather image dataset and build an image classification model with Pytorch. We hope this can be useful in responding to natural disasters. \n",
    "\n",
    "## Train an image classification model with PyTorch \n",
    "\n",
    "PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing. Image classification is a fundamental task that attempts to label an entire picture as part of a class. To learn more about image classification, see a course on computer vision from [MLU](https://github.com/aws-samples/aws-machine-learning-university-accelerated-cv).\n",
    "\n",
    "In our case, we'll be training an ML model to classifiy visual weather data into types of weather.\n",
    "- \n",
    "\n",
    "To train a custom image classification, you may train from scratch or fine tune a pre-trained model. Fine tuning is especially common to make your training more efficient and get better result in a shorter time. The model we will work with here is DenseNet-161. The densenet-161 model is one of the DenseNet group of models designed to perform image classification. If you are intersted in the model, read the [arxiv paper](https://arxiv.org/abs/1608.06993) to learn more about it.\n",
    "\n",
    "## The MWD Dataset\n",
    "\n",
    "The Multi-class Weather Dataset(MWD) for Image Classification is a valuable dataset used in the research paper entitled “Multi-class weather recognition from the still image using heterogeneous ensemble method” published by Ajayi, Gbeminiyi from University of South Africa - Science Campus. It contains 4 classes of  images: Sunrise, Shine, Rain, Cloudy. Each class has 200-350 pictures.\n",
    "\n",
    "## Steps in this notebook\n",
    "In this notebook, we will go through a few steps, they are:\n",
    "1. install packages\n",
    "2. prepare dataset\n",
    "3. dataset normalization\n",
    "4. load the DenseNet-161\n",
    "5. train(fine-tune) a model \n",
    "6. test a model \n",
    "7. show predictions graphs and confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll install python packages for later use\n",
    "\n",
    "- **torch**: [PyTorch](https://pytorch.org/) is a Python package that provides two high-level features: (1) Tensor computation (like NumPy) with strong GPU acceleration (2) Deep neural networks built on a tape-based autograd system\n",
    "\n",
    "- **torchvision**: The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
    "\n",
    "- **matplotlib**: Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (2.6.0+rocm6.2.4)\n",
      "Requirement already satisfied: filelock in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.2.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (0.21.0+rocm6.2.4)\n",
      "Requirement already satisfied: numpy in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: torch==2.6.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torchvision) (2.6.0+rocm6.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.2.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from jinja2->torch==2.6.0->torchvision) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/BLOQUE-2-CREACION-DE-MODELOS-DE-IA-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch \n",
    "%pip install torchvision\n",
    "%pip install matplotlib\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use is_available() to determine if your system supports CUDA.\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\" \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare dataset\n",
    "\n",
    "Next, you will need to download a Kaggle dataset manually from their [dataset download page](https://www.kaggle.com/pratik2901/multiclass-weather-dataset). Once you've done that, create a new folder here called \"dataset\", and upload those files into that directory. \n",
    "\n",
    "Please make sure your files looks like this once you are done.\n",
    "```\n",
    "  -- root\n",
    "    -- notebook\n",
    "    -- dataset\n",
    "      -- cloudy\n",
    "      -- rainy\n",
    "      -- shine\n",
    "      -- sunrise\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open archive.zip, archive.zip.zip or archive.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip \"archive.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: no se puede efectuar `stat' sobre 'Multi-class Weather Dataset': No existe el archivo o el directorio\n"
     ]
    }
   ],
   "source": [
    "!mv \"Multi-class Weather Dataset\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reading Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetImagesFromFolder(PATH, Class_Folder, ext):\n",
    "    \"\"\"\n",
    "    This module can be used to import image data. \n",
    "    It also takes care of resizing the images to 240x240 Pixels.\n",
    "    So that the images can be used for DenseNet-161 model fine-tuning.\n",
    "    \"\"\"\n",
    "    images = [Image.open(file).convert('RGB').resize((240,240),resample=Image.LANCZOS) for e in ext for file in glob.glob(PATH+Class_Folder+'/*.' + e)] \n",
    "    print(f\"Found {len(images)} in folder {Class_Folder}\")\n",
    "    np.random.shuffle(images)\n",
    "    return images,np.array([Class_Folder for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[32m     13\u001b[39m DATA_PATH = \u001b[33m'\u001b[39m\u001b[33m./dataset/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m FOLDERS = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(FOLDERS)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m### if you found the folder contains other subfolder than the iamge classes, \u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m### remove them before calling the label encoder\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#if os.path.exists(\"./dataset/.ipynb_checkpoints/\"):\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m#    os.rmdir(\"./dataset/.ipynb_checkpoints/\")\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './dataset/'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read the image from given path.\n",
    "1. use LabelEncoder from sklearn to encode the folder names and the class number.\n",
    "2. for each folder, add image and labels to ALL_IMAGES and ALL_LABEL.\n",
    "\"\"\"\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "DATA_PATH = './dataset/'\n",
    "FOLDERS = os.listdir(DATA_PATH)\n",
    "print(FOLDERS)\n",
    "\n",
    "### if you found the folder contains other subfolder than the iamge classes, \n",
    "### remove them before calling the label encoder\n",
    "#if os.path.exists(\"./dataset/.ipynb_checkpoints/\"):\n",
    "#    os.rmdir(\"./dataset/.ipynb_checkpoints/\")\n",
    "\n",
    "ALL_IMAGES,ALL_LABELS = [],[]\n",
    "images_population ={}\n",
    "ext = ['jpg','jpeg']\n",
    "\n",
    "for Class_Folder in FOLDERS:\n",
    "    IMAGES,LABELS = GetImagesFromFolder(DATA_PATH,Class_Folder,ext)\n",
    "    images_population[Class_Folder] = LABELS.shape[0]\n",
    "    ALL_IMAGES.extend(IMAGES)\n",
    "    ALL_LABELS.extend(LABELS)\n",
    "        \n",
    "le = LabelEncoder().fit(FOLDERS)\n",
    "print(le)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Splitting Dataset to different splits for Training, Testing & Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TRAIN_IMAGES, X_val_test, TRAIN_LABELS, y_val_test = train_test_split(ALL_IMAGES, ALL_LABELS, test_size=0.20, random_state=42,stratify=ALL_LABELS)\n",
    "VAL_IMAGES, TEST_IMAGES, VAL_LABELS, TEST_LABELS =  train_test_split(X_val_test, y_val_test, test_size=0.50, random_state=42,stratify=y_val_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create WeatherDataset class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, ImageData, Target, transform=None):\n",
    "        self.ImageData = ImageData\n",
    "        self.Target = torch.LongTensor(le.transform(Target))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.ImageData[index]\n",
    "        y = self.Target[index]\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(np.uint8(np.array(self.ImageData[index]))) # Memory Efficient way\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.ImageData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Normalization\n",
    "This is a utility function to find out MEAN & STD for Normalizing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://youtu.be/y6IEcEBRZks\n",
    "from torchvision import transforms\n",
    "def get_mean_std(loader):\n",
    "    # VAR[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_squared_sum, num_batches = 0,0,0\n",
    "    \n",
    "    for data,_ in loader:\n",
    "        channels_sum +=torch.mean(data,dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum/num_batches\n",
    "    std = (channels_squared_sum/num_batches - mean**2)**0.5\n",
    "    return mean,std\n",
    "\n",
    "batch_size = 4\n",
    "transform = transforms.Compose([transforms.Resize((230,230)),transforms.ToTensor()])\n",
    "dataset = WeatherDataset(TRAIN_IMAGES, TRAIN_LABELS, transform=transform)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=4)\n",
    "mean,std = get_mean_std(loader)\n",
    "print(f\"Data loader has:\\n*\\tmean= {mean.tolist()}\\n*\\tstd= {std.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {'train':transforms.Compose([transforms.ColorJitter(),\n",
    "                                         transforms.RandomRotation(30),\n",
    "                                         transforms.Resize((240,240)),\n",
    "                                         transforms.RandomResizedCrop(230),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=mean,std=std),#transforms.RandomErasing()\n",
    "                                        ]),\n",
    "             'val':transforms.Compose([transforms.Resize((230,230)),\n",
    "                                      transforms.ToTensor()]),\n",
    "             \n",
    "             'test':transforms.Compose([transforms.Resize((230,230)),\n",
    "                                      transforms.ToTensor()])}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "batch_size = {'train':8, 'val':8,'test':8}\n",
    "\n",
    "dataset_classes = ['Cloudy','Rain','Shine','Sunrise']\n",
    "\n",
    "\n",
    "image_datasets = {'train': WeatherDataset(TRAIN_IMAGES, TRAIN_LABELS, transform=transform['train']),\n",
    "                  'val':   WeatherDataset(VAL_IMAGES, VAL_LABELS, transform=transform['val']),\n",
    "                  'test':  WeatherDataset(TEST_IMAGES, TEST_LABELS, transform=transform['test'])\n",
    "}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val','test']}\n",
    "\n",
    "dataloaders = {indx: torch.utils.data.DataLoader(image_datasets[indx], batch_size=batch_size[indx], num_workers=4, pin_memory=True, shuffle=True)\n",
    "              for indx in batch_size.keys()}\n",
    "\n",
    "print(\"Size for Dataset:\\n\\t* Train: %d\\n\\t* Valid: %d\\n\\t* Test: %d\"%(dataset_sizes['train'],dataset_sizes['val'],dataset_sizes['test']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the DenseNet-161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def train_model(model, criterion, optimizer, model_checkpoint=0, early_stop = 10, num_epochs=5):\n",
    "    start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # number of epochs to train the model\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    early_stop_cnt = 0\n",
    "    last_epoch_loss = np.Inf\n",
    "    globaliter = 0\n",
    "\n",
    "    final_loss = np.Inf\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        globaliter+=1\n",
    "        # keep track of training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        train_corrects = 0\n",
    "\n",
    "        for data, target in dataloaders['train']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            train_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        train_loss = train_loss/len(dataloaders['train'].dataset)\n",
    "        train_acc = (train_corrects.double()*100)/len(dataloaders['train'].dataset)\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        val_corrects = 0\n",
    "        for data, target in dataloaders['val']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        # calculate average losses\n",
    "        valid_loss = valid_loss/len(dataloaders['val'].dataset)\n",
    "        valid_acc = (val_corrects.double()*100)/len(dataloaders['val'].dataset)\n",
    "\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss:  {:.6f} \\tValidation Loss:  {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "        print('\\t\\tTraining Acc:  {:.3f} \\t\\tValidation Acc:  {:.3f}'.format(train_acc, valid_acc))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('\\t\\tValidation loss decreased ({:.6f} --> {:.6f}).'.format(valid_loss_min,valid_loss))\n",
    "            if model_checkpoint != 0:\n",
    "                torch.save(model.state_dict(), '/kaggle/working/model.pt'.format(train_acc, valid_acc))\n",
    "                print('Model Saved: /kaggle/working/model.pt'.format(train_acc, valid_acc))\n",
    "            valid_loss_min = valid_loss\n",
    "        elif valid_loss == np.nan:\n",
    "            print(\"Model Loss: NAN\")\n",
    "\n",
    "        if (last_epoch_loss < valid_loss) and last_epoch_loss != np.Inf:\n",
    "            early_stop_cnt +=1\n",
    "            if early_stop_cnt == early_stop:\n",
    "                print('-'*50+\"\\nEarly Stopping Hit\\n\"+'-'*50)\n",
    "                break\n",
    "            else:\n",
    "                print('-'*50+f\"\\n\\t\\tEarly Stopping Step: {early_stop_cnt}/{early_stop}\\n\"+'-'*50)\n",
    "        else:\n",
    "            early_stop_cnt = 0\n",
    "            last_epoch_loss = valid_loss\n",
    "\n",
    "    print(f\"Training Completed with best model having loss of {round(valid_loss_min,6)}\")\n",
    "    del data,target\n",
    "    gc.collect()\n",
    "    end_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    print(f'Time Taken: {end_time-start_time}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "n_classes = 4\n",
    "epochs = 1\n",
    "\n",
    "n_classes = len(dataset_classes)\n",
    "print(n_classes)\n",
    "\n",
    "model_ft = models.densenet161(pretrained=True)\n",
    "# Using Model as Feature Extractor\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "model_ft = model_ft.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine-tune the pre-trained model on the labelled weather data\n",
    "\n",
    "Setup the hyperparameters, for example learning rate, momentum, decay and optimization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# Cross Entropy Loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "decay = 0.01\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum = momentum, weight_decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training of Model:')\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft,model_checkpoint=0,num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. test a model\n",
    "Visualize the predict label and the truth label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize = (num_images,num_images))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'Predicted: {dataset_classes[preds[j]]} | Actual: {dataset_classes[labels[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "    if device.type == 'cuda':\n",
    "        inputs = inputs.cpu()\n",
    "        labels = labels.cpu()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # Convert from tensor image\n",
    "    plt.imshow(np.transpose(img, (1,2,0)))\n",
    "    \n",
    "visualize_model(model_ft, num_images=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Show predictions graphs and confusion matrix\n",
    "- [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix): In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    size = len(classes)*2\n",
    "    plt.figure(figsize = (size,size))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title,fontsize=20)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes,fontsize=12)\n",
    "    plt.yticks(tick_marks, classes,fontsize=12)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize=16)\n",
    "    plt.xlabel('Predicted label',fontsize=16)\n",
    "\n",
    "def model_verification(loader,batch_size,model,n_classes=5):\n",
    "    classes = list(le.inverse_transform([i for i in range(n_classes)]))\n",
    "    prediction_list,label_list = [],[]\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.argmax(dim=1).detach()\n",
    "            prediction_list.extend(predicted.tolist())\n",
    "            label_list.extend(labels.tolist())\n",
    "            \n",
    "    cm = confusion_matrix(prediction_list,label_list)\n",
    "    plot_confusion_matrix(cm, classes)\n",
    "    if device.type == 'cuda':\n",
    "        inputs = inputs.cpu()\n",
    "        labels = labels.cpu()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_verification(dataloaders['val'],batch_size['val'],model_ft,n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "hcn (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
