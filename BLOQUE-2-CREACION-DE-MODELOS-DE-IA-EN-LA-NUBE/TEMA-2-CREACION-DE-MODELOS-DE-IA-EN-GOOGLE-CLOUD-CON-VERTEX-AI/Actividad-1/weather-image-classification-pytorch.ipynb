{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Classification for Disaster Risk Reduction with DenseNet-161\n",
    "[![Open In Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/aws/studio-lab-examples/blob/main/computer-vision/weather-data/weather-image-classification-pytorch.ipynb)\n",
    "\n",
    "\n",
    " Today we are going to work with a weather image dataset and build an image classification model with Pytorch. We hope this can be useful in responding to natural disasters. \n",
    "\n",
    "## Train an image classification model with PyTorch \n",
    "\n",
    "PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing. Image classification is a fundamental task that attempts to label an entire picture as part of a class. To learn more about image classification, see a course on computer vision from [MLU](https://github.com/aws-samples/aws-machine-learning-university-accelerated-cv).\n",
    "\n",
    "In our case, we'll be training an ML model to classifiy visual weather data into types of weather.\n",
    "- \n",
    "\n",
    "To train a custom image classification, you may train from scratch or fine tune a pre-trained model. Fine tuning is especially common to make your training more efficient and get better result in a shorter time. The model we will work with here is DenseNet-161. The densenet-161 model is one of the DenseNet group of models designed to perform image classification. If you are intersted in the model, read the [arxiv paper](https://arxiv.org/abs/1608.06993) to learn more about it.\n",
    "\n",
    "## The MWD Dataset\n",
    "\n",
    "The Multi-class Weather Dataset(MWD) for Image Classification is a valuable dataset used in the research paper entitled “Multi-class weather recognition from the still image using heterogeneous ensemble method” published by Ajayi, Gbeminiyi from University of South Africa - Science Campus. It contains 4 classes of  images: Sunrise, Shine, Rain, Cloudy. Each class has 200-350 pictures.\n",
    "\n",
    "## Steps in this notebook\n",
    "In this notebook, we will go through a few steps, they are:\n",
    "1. install packages\n",
    "2. prepare dataset\n",
    "3. dataset normalization\n",
    "4. load the DenseNet-161\n",
    "5. train(fine-tune) a model \n",
    "6. test a model \n",
    "7. show predictions graphs and confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll install python packages for later use\n",
    "\n",
    "- **torch**: [PyTorch](https://pytorch.org/) is a Python package that provides two high-level features: (1) Tensor computation (like NumPy) with strong GPU acceleration (2) Deep neural networks built on a tape-based autograd system\n",
    "\n",
    "- **torchvision**: The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
    "\n",
    "- **matplotlib**: Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/asier/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install torch \n",
    "#%pip install torchvision\n",
    "%pip install matplotlib\n",
    "#%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use is_available() to determine if your system supports CUDA.\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\" \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare dataset\n",
    "\n",
    "Next, you will need to download a Kaggle dataset manually from their [dataset download page](https://www.kaggle.com/pratik2901/multiclass-weather-dataset). Once you've done that, create a new folder here called \"dataset\", and upload those files into that directory. \n",
    "\n",
    "Please make sure your files looks like this once you are done.\n",
    "```\n",
    "  -- root\n",
    "    -- notebook\n",
    "    -- dataset\n",
    "      -- cloudy\n",
    "      -- rainy\n",
    "      -- shine\n",
    "      -- sunrise\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open archive.zip, archive.zip.zip or archive.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip \"archive.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: no se puede efectuar `stat' sobre 'Multi-class Weather Dataset': No existe el archivo o el directorio\n"
     ]
    }
   ],
   "source": [
    "!mv \"Multi-class Weather Dataset\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reading Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetImagesFromFolder(PATH, Class_Folder, ext):\n",
    "    \"\"\"\n",
    "    This module can be used to import image data. \n",
    "    It also takes care of resizing the images to 240x240 Pixels.\n",
    "    So that the images can be used for DenseNet-161 model fine-tuning.\n",
    "    \"\"\"\n",
    "    images = [Image.open(file).convert('RGB').resize((240,240),resample=Image.LANCZOS) for e in ext for file in glob.glob(PATH+Class_Folder+'/*.' + e)]\n",
    "    print(f\"Found {len(images)} in folder {Class_Folder}\")\n",
    "    np.random.shuffle(images)\n",
    "    return images,np.array([Class_Folder for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/archvive/Multi-class Weather Dataset/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[32m     13\u001b[39m DATA_PATH = \u001b[33m'\u001b[39m\u001b[33m./dataset/archvive/Multi-class Weather Dataset/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m FOLDERS = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(FOLDERS)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m### if you found the folder contains other subfolder than the iamge classes, \u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m### remove them before calling the label encoder\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#if os.path.exists(\"./dataset/.ipynb_checkpoints/\"):\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m#    os.rmdir(\"./dataset/.ipynb_checkpoints/\")\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './dataset/archvive/Multi-class Weather Dataset/'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read the image from given path.\n",
    "1. use LabelEncoder from sklearn to encode the folder names and the class number.\n",
    "2. for each folder, add image and labels to ALL_IMAGES and ALL_LABEL.\n",
    "\"\"\"\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "DATA_PATH = './dataset/archvive/Multi-class-Weather-Dataset/'\n",
    "FOLDERS = os.listdir(DATA_PATH)\n",
    "print(FOLDERS)\n",
    "\n",
    "### if you found the folder contains other subfolder than the iamge classes, \n",
    "### remove them before calling the label encoder\n",
    "#if os.path.exists(\"./dataset/.ipynb_checkpoints/\"):\n",
    "#    os.rmdir(\"./dataset/.ipynb_checkpoints/\")\n",
    "\n",
    "ALL_IMAGES,ALL_LABELS = [],[]\n",
    "images_population ={}\n",
    "ext = ['jpg','jpeg']\n",
    "\n",
    "for Class_Folder in FOLDERS:\n",
    "    IMAGES,LABELS = GetImagesFromFolder(DATA_PATH,Class_Folder,ext)\n",
    "    images_population[Class_Folder] = LABELS.shape[0]\n",
    "    ALL_IMAGES.extend(IMAGES)\n",
    "    ALL_LABELS.extend(LABELS)\n",
    "        \n",
    "le = LabelEncoder().fit(FOLDERS)\n",
    "print(le)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Splitting Dataset to different splits for Training, Testing & Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m TRAIN_IMAGES, X_val_test, TRAIN_LABELS, y_val_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mALL_IMAGES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mALL_LABELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mALL_LABELS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m VAL_IMAGES, TEST_IMAGES, VAL_LABELS, TEST_LABELS =  train_test_split(X_val_test, y_val_test, test_size=\u001b[32m0.50\u001b[39m, random_state=\u001b[32m42\u001b[39m,stratify=y_val_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2851\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2848\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2853\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2856\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/UNIR-IA-HERRAMIENTAS-COMPUTACION-EN-LA-NUBE/hcn/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2481\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2478\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2482\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2483\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2485\u001b[39m     )\n\u001b[32m   2487\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TRAIN_IMAGES, X_val_test, TRAIN_LABELS, y_val_test = train_test_split(ALL_IMAGES, ALL_LABELS, test_size=0.20, random_state=42,stratify=ALL_LABELS)\n",
    "VAL_IMAGES, TEST_IMAGES, VAL_LABELS, TEST_LABELS =  train_test_split(X_val_test, y_val_test, test_size=0.50, random_state=42,stratify=y_val_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create WeatherDataset class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, ImageData, Target, transform=None):\n",
    "        self.ImageData = ImageData\n",
    "        self.Target = torch.LongTensor(le.transform(Target))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.ImageData[index]\n",
    "        y = self.Target[index]\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(np.uint8(np.array(self.ImageData[index]))) # Memory Efficient way\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.ImageData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Normalization\n",
    "This is a utility function to find out MEAN & STD for Normalizing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://youtu.be/y6IEcEBRZks\n",
    "from torchvision import transforms\n",
    "def get_mean_std(loader):\n",
    "    # VAR[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_squared_sum, num_batches = 0,0,0\n",
    "    \n",
    "    for data,_ in loader:\n",
    "        channels_sum +=torch.mean(data,dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum/num_batches\n",
    "    std = (channels_squared_sum/num_batches - mean**2)**0.5\n",
    "    return mean,std\n",
    "\n",
    "batch_size = 4\n",
    "transform = transforms.Compose([transforms.Resize((230,230)),transforms.ToTensor()])\n",
    "dataset = WeatherDataset(TRAIN_IMAGES, TRAIN_LABELS, transform=transform)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=4)\n",
    "mean,std = get_mean_std(loader)\n",
    "print(f\"Data loader has:\\n*\\tmean= {mean.tolist()}\\n*\\tstd= {std.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {'train':transforms.Compose([transforms.ColorJitter(),\n",
    "                                         transforms.RandomRotation(30),\n",
    "                                         transforms.Resize((240,240)),\n",
    "                                         transforms.RandomResizedCrop(230),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=mean,std=std),#transforms.RandomErasing()\n",
    "                                        ]),\n",
    "             'val':transforms.Compose([transforms.Resize((230,230)),\n",
    "                                      transforms.ToTensor()]),\n",
    "             \n",
    "             'test':transforms.Compose([transforms.Resize((230,230)),\n",
    "                                      transforms.ToTensor()])}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "batch_size = {'train':8, 'val':8,'test':8}\n",
    "\n",
    "dataset_classes = ['Cloudy','Rain','Shine','Sunrise']\n",
    "\n",
    "\n",
    "image_datasets = {'train': WeatherDataset(TRAIN_IMAGES, TRAIN_LABELS, transform=transform['train']),\n",
    "                  'val':   WeatherDataset(VAL_IMAGES, VAL_LABELS, transform=transform['val']),\n",
    "                  'test':  WeatherDataset(TEST_IMAGES, TEST_LABELS, transform=transform['test'])\n",
    "}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val','test']}\n",
    "\n",
    "dataloaders = {indx: torch.utils.data.DataLoader(image_datasets[indx], batch_size=batch_size[indx], num_workers=4, pin_memory=True, shuffle=True)\n",
    "              for indx in batch_size.keys()}\n",
    "\n",
    "print(\"Size for Dataset:\\n\\t* Train: %d\\n\\t* Valid: %d\\n\\t* Test: %d\"%(dataset_sizes['train'],dataset_sizes['val'],dataset_sizes['test']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the DenseNet-161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def train_model(model, criterion, optimizer, model_checkpoint=0, early_stop = 10, num_epochs=5):\n",
    "    start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # number of epochs to train the model\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    early_stop_cnt = 0\n",
    "    last_epoch_loss = np.Inf\n",
    "    globaliter = 0\n",
    "\n",
    "    final_loss = np.Inf\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        globaliter+=1\n",
    "        # keep track of training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        train_corrects = 0\n",
    "\n",
    "        for data, target in dataloaders['train']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            train_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        train_loss = train_loss/len(dataloaders['train'].dataset)\n",
    "        train_acc = (train_corrects.double()*100)/len(dataloaders['train'].dataset)\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        val_corrects = 0\n",
    "        for data, target in dataloaders['val']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        # calculate average losses\n",
    "        valid_loss = valid_loss/len(dataloaders['val'].dataset)\n",
    "        valid_acc = (val_corrects.double()*100)/len(dataloaders['val'].dataset)\n",
    "\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss:  {:.6f} \\tValidation Loss:  {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "        print('\\t\\tTraining Acc:  {:.3f} \\t\\tValidation Acc:  {:.3f}'.format(train_acc, valid_acc))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('\\t\\tValidation loss decreased ({:.6f} --> {:.6f}).'.format(valid_loss_min,valid_loss))\n",
    "            if model_checkpoint != 0:\n",
    "                torch.save(model.state_dict(), '/kaggle/working/model.pt'.format(train_acc, valid_acc))\n",
    "                print('Model Saved: /kaggle/working/model.pt'.format(train_acc, valid_acc))\n",
    "            valid_loss_min = valid_loss\n",
    "        elif valid_loss == np.nan:\n",
    "            print(\"Model Loss: NAN\")\n",
    "\n",
    "        if (last_epoch_loss < valid_loss) and last_epoch_loss != np.Inf:\n",
    "            early_stop_cnt +=1\n",
    "            if early_stop_cnt == early_stop:\n",
    "                print('-'*50+\"\\nEarly Stopping Hit\\n\"+'-'*50)\n",
    "                break\n",
    "            else:\n",
    "                print('-'*50+f\"\\n\\t\\tEarly Stopping Step: {early_stop_cnt}/{early_stop}\\n\"+'-'*50)\n",
    "        else:\n",
    "            early_stop_cnt = 0\n",
    "            last_epoch_loss = valid_loss\n",
    "\n",
    "    print(f\"Training Completed with best model having loss of {round(valid_loss_min,6)}\")\n",
    "    del data,target\n",
    "    gc.collect()\n",
    "    end_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    print(f'Time Taken: {end_time-start_time}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "n_classes = 4\n",
    "epochs = 1\n",
    "\n",
    "n_classes = len(dataset_classes)\n",
    "print(n_classes)\n",
    "\n",
    "model_ft = models.densenet161(pretrained=True)\n",
    "# Using Model as Feature Extractor\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "model_ft = model_ft.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine-tune the pre-trained model on the labelled weather data\n",
    "\n",
    "Setup the hyperparameters, for example learning rate, momentum, decay and optimization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# Cross Entropy Loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "decay = 0.01\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum = momentum, weight_decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training of Model:')\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft,model_checkpoint=0,num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. test a model\n",
    "Visualize the predict label and the truth label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize = (num_images,num_images))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'Predicted: {dataset_classes[preds[j]]} | Actual: {dataset_classes[labels[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "    if device.type == 'cuda':\n",
    "        inputs = inputs.cpu()\n",
    "        labels = labels.cpu()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # Convert from tensor image\n",
    "    plt.imshow(np.transpose(img, (1,2,0)))\n",
    "    \n",
    "visualize_model(model_ft, num_images=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Show predictions graphs and confusion matrix\n",
    "- [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix): In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    size = len(classes)*2\n",
    "    plt.figure(figsize = (size,size))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title,fontsize=20)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes,fontsize=12)\n",
    "    plt.yticks(tick_marks, classes,fontsize=12)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize=16)\n",
    "    plt.xlabel('Predicted label',fontsize=16)\n",
    "\n",
    "def model_verification(loader,batch_size,model,n_classes=5):\n",
    "    classes = list(le.inverse_transform([i for i in range(n_classes)]))\n",
    "    prediction_list,label_list = [],[]\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.argmax(dim=1).detach()\n",
    "            prediction_list.extend(predicted.tolist())\n",
    "            label_list.extend(labels.tolist())\n",
    "            \n",
    "    cm = confusion_matrix(prediction_list,label_list)\n",
    "    plot_confusion_matrix(cm, classes)\n",
    "    if device.type == 'cuda':\n",
    "        inputs = inputs.cpu()\n",
    "        labels = labels.cpu()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_verification(dataloaders['val'],batch_size['val'],model_ft,n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "hcn (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
